---
title: "Milestone 2"
descriptions: |
    Functions abstracted to a file/module and addition of robust tests (`reduced.ipynb`, `.R` & `test_*.R`, function documentation)
output:
  distill::distill_article:
    toc: true
---

## Overall project summary

In this course you will work in assigned teams of three or four
(see group assignments in [Canvas](https://canvas.ubc.ca))
to answer a predictive question using a publicly available data set
that will allow you to answer that question.
To answer this question,
you will perform a complete data analysis in R and/or Python,
from data import to communication of results,
while placing significant emphasis on reproducible and trustworthy workflows.

Your data analysis project will evolve throughout the course from a single,
monolithic Jupyter notebook,
to a fully reproducible and robust data data analysis project, comprised of:

- a well documented and modularized software package and scripts written in R and/or Python,
- a data analysis pipeline automated with GNU Make,
- a reproducible report powered by either Jupyter book or R Markdown,
- a containerized computational environment created and made shareable by Docker, and
- a remote version control repository on GitHub for project collaboration and sharing,
  as well as automation of test suite execution and documentation and software deployment.

An example final project from another course (where the project is similar) can be seen here:

- [Breast Cancer Predictor](https://github.com/ttimbers/breast_cancer_predictor)

## Milestone 2 summary

In this milestone, you will:

1. Abstract some code from your literate code document (`*.Rmd`, `*.qmd`, `*.ipynb`, etc)
   to functions a modular file (e.g., `.R` or `.py`)

2. Update your project's computational environment as you add dependencies to your project

An example project milestone 2 will soon be available here:
[https://github.com/UBC-DSCI/predict-airbnb-nightly-price/tree/v2.0.0](https://github.com/UBC-DSCI/predict-airbnb-nightly-price/tree/v2.0.0)

For now, it is still a work in progress:
[https://github.com/UBC-DSCI/predict-airbnb-nightly-price](https://github.com/UBC-DSCI/predict-airbnb-nightly-price).

### 1. Abstract some code from your literate code document to functions a modular filename

- Your literate code document would be a`*.Rmd`, `*.qmd`, `*.ipynb`, etc
- Your modular functions file woule be an `*.R` or `*.py` file

In every data science project, there is some code that is repetitive,
and other code that may not be repetitive in the current project,
but would likely be very useful in other, related future projects.
It is well worth it to abstract such code to functions.
This allows for the code to be tested with unit tests, to ensure it works as expected,
as well as makes it easily reuseable in the future in other work.

Examples of code that often repetitive in a data analysis projects:

- data wrangling, cleaning or transformation code that gets applied to multiple columns or multiple data sets
- data visualization code when many versions of a similar plot-type is used
  (e.g., many scatter plots with similar formatting)
- data modeling workflow/pipeline code when tuning different models on the same data set

When doing this task,
follow the
[workflow for writing functions and tests for data science](https://ubc-dsci.github.io/reproducible-and-trustworthy-workflows-for-data-science/materials/lectures/06-intro-to-testing-code.html#workflow-for-writing-functions-and-tests-for-data-science),
remember this process will include:

  - writing thorough function specifications & documentation
  - writing robust unit tests for these functions to ensure they work as expected
  - writing the code that makes up the function body

If you are using R, these functions will live in an `.R` file
(whose filename will be named after the function, or functions).
It is OK to have one function per file, or all functions in one file.
This/these file(s) will live in a sub-directory called `R`.

If you are using Python, these functions will live in an `.py` file
(whose filename will be named after the function, or functions).
Again, it is OK to have one function per file, or all functions in one file.
This/these file(s) will live in a sub-directory called `src`.

You will `source` (in the case of R) or `import` (in the case of Python)
these functions in your literate code document (`*.ipynb`) to use them in your analysis.
Tests will live in a `test` directory, with files/subdirectories organized as per the testing framework you are using.

**We expect that you will abstract at least 3-4 functions from your literate code document.
One per group member is the minimum.**
Of course, if it makes sense to have more than 3-4 you are welcome to increase the number!
However, all functions must have the same standards in regards to software robustness.
Your functions will be assessed for their quality
(e.g., functions should do one thing,
and generally return an object unless they were specifically designed for side-effects),
usability,
readability (follow the [tidyverse style guide](https://style.tidyverse.org/) for R,
or the [black style guide](https://black.readthedocs.io/en/stable/the_black_code_style/index.html) for Python),
documentation and quality of the test suite.

If you are using R for your data analysis code,
we expect you to use the [`testthat`](https://testthat.r-lib.org/) R package framework for writing software tests.
If you are using Python, we expect you to use the [`pytest`](https://docs.pytest.org/en/7.0.x/) Python package framework.

### 2. Update your project's computational environment as you add dependencies to your project

At a minimum, you will be adding the testing package framework as a new dependency to your project
(e.g., `testthat` R package or `pytest` Python package).
Thus, you will need to update your project's computational environment
as you add this (and potentially other) dependencies to your project.
This means that your `Dockerfile` will need to have this package added, with the version pinned,
and the Docker container image will need to be rebuilt.
Do not forget to update your project's documentation to reflect these changes.

## Submission Instructions

You will submit two URLS's to Canvas in the provided text box for milestone 2:

1. the URL of your project's GitHub.com repository
2. the URL of a GitHub release of your project's GitHub.com repository for this milestone.

### Creating a release on GitHub.com

Just before you submit the milestone 2,
create a release on your project repository on GitHub and name it something like `2.0.0`
([how to create a release](https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository#creating-a-release)).
This release allows us and you to easily jump to the state of your repository at the time of submission for grading puroposes,
while you continue to work on your project for the next milestone.

## Expectations

- **Everyone should contribute equally to all aspects of the project**
  **(e.g., code, writing, project management).**
  **This should be evidenced by a roughly equal number of commits,**
  **pull request reviews and participation in communication via GitHub issues.**
- Each group member should work in a
  [GitHub flow workflow](https://docs.github.com/en/get-started/quickstart/github-flow);
  where they create branches for each feature or fix,
  which are reviewed and critiqued by at least one other teammate
  before the the pull request is accepted.
- You should be committing to git and pushing to GitHub.com every time you work on this project.
- Git commit messages should be meaningful. These will be marked.
  It's OK if one or two are less meaningful, but most should be.
- Use GitHub issues to communicate to their team mate (as opposed to email or Slack).
- Your question, analysis and visualization should make sense. It doesn't have to be complicated.
- **Your analysis should be correct, and run reproducibly given the instructions provided in the README.**
- You should use proper grammar and full sentences in your README.
  Point form may occur, but should be less than 10% of your written documents.
- You will not be expected to incorporate Milestone 1 feedback in this submission.
